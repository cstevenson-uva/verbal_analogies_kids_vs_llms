Dublin Core Metadata
---------------------------------------------

Title:
Verbal Analogies Children versus LLMs

Creator:
Stevenson, Claire

Subject:
Codebook variables

Description:
This codebook provides detailed information on the variables and the units of measurements created and used.

Publisher:
University of Amsterdam

Contributor:
Mathilde ter Veen, Rochelle Choenni, Han L. J. van der Maas⋄ and Ekaterina Shutova

Date:
2023-11-01

Type:
Codebook

Format:
text/plain

Identifier:
-

Source:
Prowise Learn Verbal Analogies Game

Language:
English

Relation:
Full dataset of items and children's performance available from Prowise Learn BV

Coverage:
The Netherlands, 2023

Rights:
-


Description variables
--------------------
1. row_number
- Description: Unique row number given to verbal analogy problem.
- Unit of Measurement: Numeric identifier	

2. item_number
- Description: Unique number given to verbal analogy problem.
- Unit of Measurement: Numeric identifier	

3. semantic_distance_near_far
- Description: Conceptual Distance Between Base and Target Domains. The greater the distance between an analogy base and target domain the more difficult the analogy is for adults and children to solve. It is measured by determining the cosine distance between the A:B and the C:D pair. The distances are categorized as near (distance ranging from 0-.35), middle (.36-.64) or far distance (.65-1.0). 
- Unit of Measurement: Categorical (Nominal)
- Categories: near, middle, far	

4. distractor_salience_high_low
- Description: The relation between C:D relative to each of the C:D’, where D’ represents each distractor option. Distractor salience is high, when the semantic similarity between C and one of the incorrect answers D’ is greater than the semantic similarity between C and the correct answer D. 
- Unit of Measurement: Categorical (Nominal)
- Categories: high, low

5. type_relation_jones
- Description: The relationship between the A and B term and the C and D term of verbal analogy problems, according to Jones (2022) 
- Unit of Measurement: Categorical (Nominal)
- Categories: categorical, compositional, causal	

6. result_w2v
- Description: The outcome of solving the verbal analogy problems using the Word2vec model.
- Unit of Measurement: Categorical (Nominal)
- Categories: 0 (incorrectly solved), 1 (correctly solved)	

7. result_ft
- Description: The outcome of solving the verbal analogy problems using the Fasttext model.
- Unit of Measurement: Categorical (Nominal)
- Categories: 0 (incorrectly solved), 1 (correctly solved)	

8. result_mgpt
- Description: The outcome of solving the verbal analogy problems using the MGPT model.
- Unit of Measurement: Categorical (Nominal)
- Categories: 0 (incorrectly solved), 1 (correctly solved) 	

9. result_gpt2
- Description: The outcome of solving the verbal analogy problems using the Dutch GPT2 model.
- Unit of Measurement: Categorical (Nominal)
- Categories: 0 (incorrectly solved), 1 (correctly solved)	

10. result_bertje
- Description: The outcome of solving the verbal analogy problems using the Bertje model.
- Unit of Measurement: Categorical (Nominal)
- Categories: 0 (incorrectly solved), 1 (correctly solved)	

11. result_robbert
- Description: The outcome of solving the verbal analogy problems using the RobBERT model.
- Unit of Measurement: Categorical (Nominal)
- Categories: 0 (incorrectly solved), 1 (correctly solved)

12. result_xlm
- Description: The outcome of solving the verbal analogy problems using the XLM-V model.
- Unit of Measurement: Categorical (Nominal)
- Categories: 0 (incorrectly solved), 1 (correctly solved)

13. result_gpt3
- Description: The outcome of solving the verbal analogy problems using the GPT3 model.
- Unit of Measurement: Categorical (Nominal)
- Categories: 0 (incorrectly solved), 1 (correctly solved)
